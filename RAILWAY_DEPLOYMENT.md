# Railway Deployment Guide - ElasticBot Backend

## Architecture Overview

ElasticBot runs **THREE processes in a SINGLE container** using supervisord:

1. **Web** - Django REST API (Gunicorn) on port 8000
2. **Worker** - Celery Worker (async task processing)
3. **Beat** - Celery Beat (scheduled task scheduler)

This simplifies deployment to **ONE Railway service** instead of three.

---

## Prerequisites

1. Railway account with a project
2. Redis addon (or external Redis like Upstash)
3. PostgreSQL database (Railway Postgres or external)
4. Environment variables configured

---

## Step-by-Step Setup

### Step 1: Configure the Backend Service

Your service `ficct-elasticbot-backend` already exists. Just update the environment variables:

1. Go to Railway Dashboard â†’ `ficct-elasticbot-backend` â†’ **Variables**
2. Add/update these variables:

```env
# Required
PORT=8000
DEBUG=False
SECRET_KEY=your-secret-key
DATABASE_URL=${{Postgres.DATABASE_URL}}
ALLOWED_HOSTS=your-domain.railway.app,localhost

# Redis & Celery
REDIS_URL=${{Redis.REDIS_URL}}
CELERY_BROKER_URL=${{Redis.REDIS_URL}}
CELERY_RESULT_BACKEND=${{Redis.REDIS_URL}}

# Supervisord process configuration
GUNICORN_WORKERS=4
GUNICORN_TIMEOUT=120
CELERY_CONCURRENCY=2
CELERY_LOG_LEVEL=info
```

3. **Redeploy** the service

That's it! The single container runs all three processes via supervisord.

---

## Complete Environment Variables Reference

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | HTTP port for Gunicorn | `8000` |
| `SECRET_KEY` | Django secret key | Required |
| `DATABASE_URL` | PostgreSQL connection | Required |
| `REDIS_URL` | Redis connection | Required |
| `CELERY_BROKER_URL` | Celery broker URL | Required |
| `CELERY_RESULT_BACKEND` | Celery results backend | Required |
| `ALLOWED_HOSTS` | Django allowed hosts | `localhost` |
| `GUNICORN_WORKERS` | Number of Gunicorn workers | `4` |
| `GUNICORN_TIMEOUT` | Request timeout seconds | `120` |
| `CELERY_CONCURRENCY` | Celery worker concurrency | `2` |
| `CELERY_LOG_LEVEL` | Celery log level | `info` |
| `DEBUG` | Django debug mode | `False` |

### Optional (API Keys)

| Variable | Description |
|----------|-------------|
| `AWS_ACCESS_KEY_ID` | AWS for Bedrock AI |
| `AWS_SECRET_ACCESS_KEY` | AWS for Bedrock AI |
| `AWS_DEFAULT_REGION` | AWS region |

---

## Verification

### 1. Check Startup Logs

When the container starts, you should see:

```
============================================================
ğŸš€ ElasticBot Backend - Multi-Process Startup
============================================================
Time: Sat Nov 30 18:00:00 UTC 2025
============================================================

ğŸ“¡ Checking database connection...
âœ… Database connection OK

ğŸ“¦ Running database migrations...
âœ… Migrations complete

ğŸ“ Collecting static files...
âœ… Static files collected

============================================================
ğŸ“‹ Configuration:
   PORT: 8000
   GUNICORN_WORKERS: 4
   CELERY_CONCURRENCY: 2
   CELERY_LOG_LEVEL: info
============================================================

ğŸ¬ Starting supervisord with 3 processes:
   1. ğŸŒ Web (Gunicorn) - HTTP API server
   2. âš™ï¸  Worker (Celery) - Async task processor
   3. â° Beat (Celery Beat) - Scheduled task sender

ğŸ“… Scheduled Tasks:
   - P2P Scrape: Every 30 min (XX:00, XX:30)
   - BCB Rate: Daily at 8:00 AM Bolivia
   - Cleanup: Weekly on Sundays
============================================================
```

### 2. Check Process Logs

After supervisord starts, you'll see:

```
======================================================
ğŸŒ [WEB] STARTING GUNICORN SERVER...
======================================================
[INFO] Starting gunicorn 21.x.x
[INFO] Listening at: http://0.0.0.0:8000

======================================================
âš™ï¸  [WORKER] STARTING CELERY WORKER...
======================================================
[INFO] celery@hostname ready.

======================================================
â° [BEAT] STARTING CELERY BEAT SCHEDULER...
======================================================
[INFO] beat: Starting...
```

### 3. Verify Scheduled Tasks

Wait for the next :00 or :30 minute mark and check:
```sql
SELECT timestamp, average_sell_price 
FROM market_data_marketsnapshot 
ORDER BY timestamp DESC 
LIMIT 5;
```

Expected pattern (every 30 minutes):
```
2025-11-30 14:00:00  â†’  10.12
2025-11-30 14:30:00  â†’  10.11
2025-11-30 15:00:00  â†’  10.13
2025-11-30 15:30:00  â†’  10.12
```

---

## Scheduled Tasks

The following tasks run automatically:

| Task | Schedule | Description |
|------|----------|-------------|
| `fetch-binance-p2p-frequent` | Every 30 min | P2P market data scraping |
| `fetch-bcb-exchange-rate-daily` | Daily 8 AM (Bolivia) | BCB official rate |
| `cleanup-old-snapshots` | Weekly Sunday 3 AM | Data cleanup |

---

## Troubleshooting

### Worker not connecting to Redis

Check `CELERY_BROKER_URL` is correct:
```bash
# In Railway, use the reference syntax:
CELERY_BROKER_URL=${{Redis.REDIS_URL}}
```

### Beat not scheduling tasks

1. Verify `django_celery_beat` tables exist:
   ```bash
   python manage.py migrate django_celery_beat
   ```
2. Check beat logs for "Schedule changed" message

### No snapshots being created

1. Check Worker logs for task execution
2. Verify Beat is sending tasks
3. Check for errors in `fetch_binance_data` task

---

## Quick Reference Commands

### Local Testing with Docker Compose
```bash
# Start all services locally
docker-compose up -d

# View logs
docker-compose logs -f web
docker-compose logs -f worker
docker-compose logs -f beat

# Stop all
docker-compose down
```

### Manual Task Execution (Debugging)
```bash
# SSH into Railway or run locally
python manage.py run_scraper
```

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Railway Project                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              ficct-elasticbot-backend                   â”‚ â”‚
â”‚  â”‚                  (Single Container)                     â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚              SUPERVISORD                         â”‚   â”‚ â”‚
â”‚  â”‚  â”‚                                                  â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚   Web    â”‚  â”‚  Worker  â”‚  â”‚   Beat   â”‚      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Gunicorn â”‚  â”‚  Celery  â”‚  â”‚  Celery  â”‚      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  :8000   â”‚  â”‚  async   â”‚  â”‚scheduler â”‚      â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                            â”‚                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚              Redis                   â”‚             â”‚
â”‚         â”‚     (Broker + Result Backend)        â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                            â”‚                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚         â”‚           PostgreSQL                 â”‚             â”‚
â”‚         â”‚          (Database)                  â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Success Criteria

âœ… **ONE Railway service** running with supervisord managing 3 processes

âœ… Logs show:
- `ğŸš€ ElasticBot Backend - Multi-Process Startup`
- `ğŸŒ [WEB] STARTING GUNICORN SERVER...`
- `âš™ï¸  [WORKER] STARTING CELERY WORKER...`
- `â° [BEAT] STARTING CELERY BEAT SCHEDULER...`

âœ… Database receiving new MarketSnapshots every **30 minutes exactly**:
```
14:00 â†’ 14:30 â†’ 15:00 â†’ 15:30 â†’ 16:00 ...
```

âœ… At least **FOUR consecutive snapshots** with ~30 minute spacing
